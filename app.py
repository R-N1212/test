# RAG_vectorãƒ•ã‚¡ã‚¤ãƒ«äºŒã¤ã‚’å¯¾è±¡ã¨ã™ã‚‹å½¢å¼ï¼ˆãƒãƒ‹ãƒ¥ã‚¢ãƒ«ã€FAQï¼‰

import streamlit as st
import pickle
import numpy as np
import os
from sentence_transformers import SentenceTransformer
from openai import OpenAI

# === âœ… ãƒšãƒ¼ã‚¸è¨­å®š ===
st.set_page_config(page_title="ç¤¾å†…RAGãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ", layout="wide")
st.title("ğŸ“˜ ç¤¾å†…ãƒ«ãƒ¼ãƒ«ç›¸è«‡ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ")

# === âœ… ãƒ¢ãƒ‡ãƒ«ã¨ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ï¼ˆFAQ + ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ï¼‰ ===
@st.cache_resource
def load_model_and_data():
    model = SentenceTransformer("all-MiniLM-L6-v2")

    # FAQãƒ‡ãƒ¼ã‚¿
    with open("vector_store_faq.pkl", "rb") as f:
        faq_data = pickle.load(f)

    # ãƒãƒ‹ãƒ¥ã‚¢ãƒ«ãƒ‡ãƒ¼ã‚¿
    with open("vector_store.pkl", "rb") as f:
        manual_data = pickle.load(f)

    return model, faq_data, manual_data

model, faq_data, manual_data = load_model_and_data()

# === âœ… OpenAIã‚­ãƒ¼ã®èª­ã¿è¾¼ã¿ï¼ˆsecrets.toml çµŒç”±ï¼‰ ===
api_key = st.secrets["OPENAI_API_KEY"]
client = OpenAI(api_key=api_key)

# === âœ… ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›æ¬„ ===
query = st.text_input("ğŸ’¬ è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")

if st.button("å›ç­”ã‚’ç”Ÿæˆ") and query:
    query_vec = model.encode(query)

    # âœ… ã‚¹ã‚³ã‚¢ä»˜ãæ¤œç´¢é–¢æ•°ï¼ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æŸ”è»Ÿå¯¾å¿œ + é¡ä¼¼åº¦è¿”å´ï¼‰
    def search_similar_docs(data, query_vec, top_k=3):
        for field_option in ["body", "answer"]:
            if field_option in data[0]:
                target_field = field_option
                break
        else:
            raise KeyError("å¯¾è±¡ãƒ‡ãƒ¼ã‚¿ã« 'body' ã¾ãŸã¯ 'answer' ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

        embeddings = [model.encode(d[target_field]) for d in data]
        similarities = np.dot(embeddings, query_vec) / (
            np.linalg.norm(embeddings, axis=1) * np.linalg.norm(query_vec)
        )
        top_indices = np.argsort(similarities)[-top_k:][::-1]
        top_docs = [data[i] for i in top_indices]
        top_scores = [similarities[i] for i in top_indices]
        return top_docs, top_scores

    # === âœ… FAQå„ªå…ˆ â†’ ã‚¹ã‚³ã‚¢ä½ã‘ã‚Œã°ãƒãƒ‹ãƒ¥ã‚¢ãƒ«æ¤œç´¢ã¸åˆ‡ã‚Šæ›¿ãˆ ===
    top_faq, faq_scores = search_similar_docs(faq_data, query_vec)
    THRESHOLD = 0.6  # é¡ä¼¼åº¦ã®ã—ãã„å€¤ï¼ˆ0ã€œ1ï¼‰

    if max(faq_scores) >= THRESHOLD:
        retrieved_label = "FAQ"
        retrieved_docs = top_faq
    else:
        top_manual, _ = search_similar_docs(manual_data, query_vec)
        retrieved_label = "ãƒãƒ‹ãƒ¥ã‚¢ãƒ«"
        retrieved_docs = top_manual

    # === âœ… ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä½œæˆ ===
    def format_docs(label, docs):
        return f"\n--- {label} ---\n" + "\n".join(
            f"{doc.get('title', 'Q&A')}ï¼ˆ{doc.get('article', '')}ï¼‰: {doc.get('body', doc.get('answer', ''))}"
            for doc in docs
        )

    retrieved_text = format_docs(retrieved_label, retrieved_docs)

    prompt = f"""ä»¥ä¸‹ã®ç¤¾å†…è³‡æ–™ã«åŸºã¥ãã€è³ªå•ã«ä¸å¯§ã«ç­”ãˆã¦ãã ã•ã„ã€‚

{retrieved_text}

è³ªå•:
{query}

å›ç­”:"""

    # === âœ… ChatGPTã§å›ç­”ç”Ÿæˆ ===
    with st.spinner("å›ç­”ã‚’ç”Ÿæˆä¸­..."):
        try:
            response = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=[
                    {"role": "system", "content": "ã‚ãªãŸã¯ç¤¾å†…è¦å®šã«è©³ã—ã„ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚"},
                    {"role": "user", "content": prompt},
                ],
                temperature=0.3,
            )
            answer = response.choices[0].message.content
            st.success("âœ… å›ç­”ã¯ã“ã¡ã‚‰")
            st.markdown(answer)
        except Exception as e:
            st.error(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

elif not query:
    st.info("ğŸ’¬ è³ªå•ã‚’å…¥åŠ›å¾Œã€[å›ç­”ã‚’ç”Ÿæˆ]ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦ãã ã•ã„")
